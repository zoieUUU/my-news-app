import streamlit as st
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai

# 1. AI ì—”ì§„ ì„¤ì • (404 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ìµœí›„ì˜ ìˆ˜ë‹¨)
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    # ê²½ë¡œ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ models/ ë¥¼ í¬í•¨í•œ ì „ì²´ ê²½ë¡œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‘ì„±
    model = genai.GenerativeModel('models/gemini-1.5-flash')
except Exception as e:
    st.error(f"API ì„¤ì • ì˜¤ë¥˜: {e}")

st.set_page_config(page_title="VIRAL RANKING MASTER", layout="wide")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (ì°¨ë‹¨ ë°©ì§€ ë¡œì§ ê°•í™”) ---
@st.cache_data(ttl=600)
def get_viral_top_100():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        unique_news = []
        seen_titles = set()
        for box in soup.select('.rankingnews_box'):
            for li in box.select('.rankingnews_list li'):
                a_tag = li.select_one('a')
                if a_tag:
                    title = a_tag.text.strip()
                    if title not in seen_titles:
                        unique_news.append({"title": title, "link": a_tag['href']})
                        seen_titles.add(title)
        
        # Sê¸‰ ì†Œì¬ ì„ ë³„ (ìƒìœ„ 40ê°œ ë¶„ì„)
        titles_chunk = "\n".join([f"{i}. {d['title']}" for i, d in enumerate(unique_news[:40])])
        prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ì¤‘ ìœ íŠœë¸Œ ì¡°íšŒìˆ˜ê°€ í„°ì§ˆ Sê¸‰ ì†Œì¬ 5ê°œì˜ ë²ˆí˜¸ë§Œ ê³¨ë¼ì¤˜: {titles_chunk}"
        resp = model.generate_content(prompt)
        # ì‘ë‹µì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ëŠ” ì•ˆì „í•œ ë¡œì§
        import re
        s_indices = [int(n) for n in re.findall(r'\d+', resp.text)]
    except:
        s_indices = [0, 1, 2, 3, 4]
    
    for i, item in enumerate(unique_news):
        item['is_s'] = i in s_indices
    return sorted(unique_news, key=lambda x: x['is_s'], reverse=True)

# --- AI ë¶„ì„ í•¨ìˆ˜ (ë„¤ì´ë²„ ì°¨ë‹¨ ìš°íšŒ ë° 404 ì—ëŸ¬ ë°©ì§€) ---
def get_ai_analysis(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://news.naver.com/"
        }
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ìˆ˜ì§‘ íƒœê·¸ (ìµœì‹ ìˆœ)
        content = soup.select_one('#dic_area') or soup.select_one('#newsct_article') or soup.select_one('#articleBodyContents')
        
        if not content:
            return "ê¸°ì‚¬ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "ë¶„ì„ ë¶ˆê°€"
            
        text = content.get_text(strip=True)
        # AI ë¶„ì„ ìš”ì²­ (í•µì‹¬ ìš”ì•½ ë° í‚¤ì›Œë“œ)
        analysis_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•´ì„œ [ìš”ì•½ 2ì¤„]ê³¼ [í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ]ë¥¼ ì¶œë ¥í•´:\n\n{text[:1800]}"
        resp = model.generate_content(analysis_prompt)
        return text, resp.text
    except Exception as e:
        # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì¶œë ¥
        return f"ì—°ê²° ì‹¤íŒ¨: {str(e)}", f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ëª¨ë¸ í˜¸ì¶œ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ)"

# --- UI êµ¬ì„± ---
st.title("ğŸ”¥ VIRAL RANKING MASTER")

left_col, right_col = st.columns([1, 1.2])

with left_col:
    if st.button("ğŸ”„ ë¦¬ìŠ¤íŠ¸ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()
    
    data = get_viral_top_100()
    for i, item in enumerate(data):
        if item['is_s']:
            # Sê¸‰ ê°•ì¡° ë””ìì¸
            st.markdown(f'<div style="background-color:#FFD700; padding:4px 8px; border-radius:4px; border:2px solid #FFA500; font-weight:bold; color:black; font-size:12px; margin-bottom:-10px; width:fit-content;">ğŸ‘‘ AI S-CLASS</div>', unsafe_allow_html=True)
            if st.button(f"ğŸ”¥ {item['title']}", key=f"s_{i}", use_container_width=True):
                with st.spinner('AI ë¶„ì„ ì¤‘...'):
                    t, a = get_ai_analysis(item['link'])
                    st.session_state.result = {"title": item['title'], "text": t, "analysis": a}
        else:
            if st.button(f"[{i+1}] {item['title']}", key=f"n_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = get_ai_analysis(item['link'])
                    st.session_state.result = {"title": item['title'], "text": t, "analysis": a}

with right_col:
    st.subheader("ğŸ“Š AI ì†Œì¬ ë¶„ì„ ë¦¬í¬íŠ¸")
    if "result" in st.session_state:
        # AI ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶œë ¥
        st.success(f"**ğŸ’¡ AI ì¸ì‚¬ì´íŠ¸**\n\n{st.session_state.result['analysis']}")
        st.divider()
        st.info(f"**ì œëª©: {st.session_state.result['title']}**")
        st.text_area("ê¸°ì‚¬ ì „ë¬¸", st.session_state.result['text'], height=550)
    else:
        st.info("ğŸ‘ˆ ì™¼ìª½ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¶„ì„í•  ê¸°ì‚¬ë¥¼ í´ë¦­í•´ ì£¼ì„¸ìš”.")
