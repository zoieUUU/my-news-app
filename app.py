import streamlit as st
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import re

# 1. AI ì—”ì§„ ì„¤ì • (ê°€ìš© ëª¨ë¸ ìë™ íƒìƒ‰)
@st.cache_resource
def load_ai_model():
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target = 'models/gemini-1.5-flash' if 'models/gemini-1.5-flash' in models else models[0]
        return genai.GenerativeModel(target)
    except: return None

model = load_ai_model()

st.set_page_config(page_title="VIRAL RANKING MASTER", layout="wide")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë“±ê¸‰ íŒë³„ ---
@st.cache_data(ttl=600)
def get_viral_top_100():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    unique_news = []
    seen = set()
    for box in soup.select('.rankingnews_box'):
        for li in box.select('.rankingnews_list li'):
            a = li.select_one('a')
            if a and a.text.strip() not in seen:
                unique_news.append({"title": a.text.strip(), "link": a['href']})
                seen.add(a.text.strip())
    
    if model:
        try:
            titles = "\n".join([f"{i}. {d['title']}" for i, d in enumerate(unique_news[:30])])
            resp = model.generate_content(f"ìœ íŠœë¸Œ ì¡°íšŒìˆ˜ 100ë§Œ ê¸°ì¤€ Sê¸‰ ì†Œì¬ 5ê°œ ë²ˆí˜¸ë§Œ ê³¨ë¼(ì‰¼í‘œ êµ¬ë¶„): {titles}")
            s_indices = [int(n) for n in re.findall(r'\d+', resp.text)]
        except: s_indices = [0,1,2,3,4]
    
    for i, item in enumerate(unique_news):
        item['grade'] = "S" if i in s_indices else "A"
    return sorted(unique_news, key=lambda x: x['grade'], reverse=True)

# --- ë‰´ìŠ¤ ë¶„ì„ í•¨ìˆ˜ ---
def analyze_news(url):
    headers = {"User-Agent": "Mozilla/5.0", "Referer": "https://news.naver.com/"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    content = soup.select_one('#dic_area') or soup.select_one('#newsct_article') or soup.select_one('#articleBodyContents')
    text = content.get_text(strip=True) if content else "ë³¸ë¬¸ ìˆ˜ì§‘ ë¶ˆê°€"
    
    analysis = "ë¶„ì„ ì‹¤íŒ¨"
    if model and text != "ë³¸ë¬¸ ìˆ˜ì§‘ ë¶ˆê°€":
        prompt = f"ì´ ê¸°ì‚¬ì˜ í•µì‹¬ ìš”ì•½ 2ì¤„ê³¼ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ë½‘ì•„ì¤˜:\n\n{text[:1500]}"
        try:
            analysis = model.generate_content(prompt).text
        except: pass
    return text, analysis

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ”¥ VIRAL RANKING MASTER")

l, r = st.columns([1, 1.2])

with l:
    if st.button("ğŸ”„ ë¦¬ìŠ¤íŠ¸ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()
    
    data = get_viral_top_100()
    for i, item in enumerate(data):
        if item['grade'] == "S":
            st.markdown(f'<div style="background-color:#FFD700; padding:5px; border-radius:5px; border:2px solid #FFA500; font-weight:bold; color:black; font-size:12px; margin-bottom:-10px; width:fit-content;">ğŸ‘‘ AI S-CLASS ì¶”ì²œ</div>', unsafe_allow_html=True)
            if st.button(f"ğŸ”¥ {item['title']}", key=f"s_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = analyze_news(item['link'])
                    st.session_state.res = {"title":item['title'], "text":t, "analysis":a, "link":item['link']}
        else:
            if st.button(f"[{i+1}] {item['title']}", key=f"n_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = analyze_news(item['link'])
                    st.session_state.res = {"title":item['title'], "text":t, "analysis":a, "link":item['link']}

with r:
    st.subheader("ğŸ“Š AI ë¶„ì„ ë¦¬í¬íŠ¸")
    if "res" in st.session_state:
        # ìš”ì•½ ê²°ê³¼
        st.success(f"**ğŸ’¡ AI ì¸ì‚¬ì´íŠ¸**\n\n{st.session_state.res['analysis']}")
        
        # [í•µì‹¬] ì›ë¬¸ ë§í¬ ë° ë³µì‚¬ ë²„íŠ¼
        st.divider()
        st.markdown(f"ğŸ”— **[ë„¤ì´ë²„ ì›ë¬¸ ê¸°ì‚¬ ì½ê¸°]({st.session_state.res['link']})**")
        
        st.info(f"**ì œëª©: {st.session_state.res['title']}**")
        st.text_area("ê¸°ì‚¬ ë³¸ë¬¸ (í´ë¡œë“œ ê°€ê³µìš©)", st.session_state.res['text'], height=400)
        
        # í´ë¡œë“œìš© í†µí•© í”„ë¡¬í”„íŠ¸
        st.markdown("### ğŸ“¥ Claude ë³µì‚¬ìš© í”„ë¡¬í”„íŠ¸")
        copy_text = f"ì œëª©: {st.session_state.res['title']}\nì¶œì²˜: {st.session_state.res['link']}\n\në‚´ìš©: {st.session_state.res['text']}"
        st.code(copy_text, language="text")
    else:
        st.info("ğŸ‘ˆ ì†Œì¬ë¥¼ ì„ íƒí•˜ë©´ ìƒì„¸ ë¶„ì„ê³¼ ë§í¬ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
