import streamlit as st
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import PIL.Image
import io
import json
import time
import re

# 1. AI ì—”ì§„ ì„¤ì • - ëª¨ë¸ëª… ê³ ì • ë° ìºì‹œ ê°•ì œ ì´ˆê¸°í™” ë¡œì§
# ìºì‹œ íŒŒë¼ë¯¸í„°(hash_funcs)ë¥¼ ì¶”ê°€í•˜ì—¬ ì´ì „ 1.5-flash ìºì‹œë¥¼ ì™„ì „íˆ ë¬´íš¨í™”í•©ë‹ˆë‹¤.
@st.cache_resource(show_spinner=False, hash_funcs={genai.GenerativeModel: lambda _: None})
def load_ai_model(version_tag="v2.6_stable"):
    try:
        # Canvas í™˜ê²½ ì „ìš© ìµœì‹  ëª¨ë¸ëª…
        target_model = 'gemini-2.5-flash-preview-09-2025'
        
        # API í‚¤ ì„¤ì •
        api_key = st.secrets.get("GOOGLE_API_KEY", "")
        genai.configure(api_key=api_key)
        
        # ëª¨ë¸ ê°ì²´ ìƒì„± (ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ëª…ì„ ë‹¤ì‹œ ì£¼ì…)
        model = genai.GenerativeModel(model_name=target_model)
        return model
    except Exception as e:
        st.error(f"AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (ë²„ì „ íƒœê·¸ë¥¼ ë³€ê²½í•˜ì—¬ ìºì‹œ ë¦¬í”„ë ˆì‹œ ìœ ë„)
ai_engine = load_ai_model(version_tag="fixed_404_v1")

# 2. AI í˜¸ì¶œ í•¨ìˆ˜ - ì—ëŸ¬ ë°©ì–´ ë° ë¦¬ë¼ì´íŠ¸ ë¡œì§
def call_gemini_api(prompt, is_image=False, images=None):
    if not ai_engine:
        # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì¬ì‹œë„ ìœ ë„
        st.warning("AI ì—”ì§„ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ì„ ì‹œë„í•˜ì„¸ìš”.")
        return None
    
    max_retries = 3
    for i in range(max_retries):
        try:
            if is_image and images:
                response = ai_engine.generate_content([prompt, *images])
            else:
                response = ai_engine.generate_content(prompt)
            return response
        except Exception as e:
            error_msg = str(e).lower()
            
            # 404 ì—ëŸ¬ ë°œìƒ ì‹œ (ê°€ì¥ ë¬¸ì œë˜ëŠ” ë¶€ë¶„)
            if "404" in error_msg or "not found" in error_msg:
                # ì¦‰ê°ì ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìºì‹œ ì‚­ì œ ê°€ì´ë“œ ì œê³µ
                st.error("âš ï¸ ì‹œìŠ¤í…œì— êµ¬í˜• ëª¨ë¸ ì •ë³´ê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. ìš°ì¸¡ ìƒë‹¨ 'Clear Cache' í›„ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
                return None
                
            # 429 ì—ëŸ¬ ë°œìƒ ì‹œ (í• ë‹¹ëŸ‰ ì´ˆê³¼)
            if "429" in error_msg or "quota" in error_msg:
                wait_time = 15 + (i * 10)
                status_box = st.empty()
                status_box.warning(f"â³ API í•œë„ ë„ë‹¬: {wait_time}ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...")
                time.sleep(wait_time)
                status_box.empty()
                continue
                
            st.error(f"AI í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            break
    return None

st.set_page_config(page_title="VIRAL MASTER PRO v2.6", layout="wide")

# --- UI ë””ìì¸ ---
st.markdown("""
    <style>
    div.stButton > button {
        text-align: left !important;
        border-radius: 10px !important;
        padding: 12px !important;
        margin-bottom: 4px;
        width: 100%;
        border: 1px solid #ddd !important;
        background-color: white !important;
    }
    div.stButton > button:has(div:contains("ğŸ†")) {
        background-color: #fff9e6 !important;
        border: 2px solid #FFD700 !important;
        font-weight: bold !important;
    }
    .stTabs [data-baseweb="tab"] {
        font-size: 18px;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ---
@st.cache_data(ttl=600)
def fetch_top_news():
    try:
        url = "https://news.naver.com/main/ranking/popularDay.naver"
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, 'html.parser')
        news_list = []
        for box in soup.select('.rankingnews_box'):
            for li in box.select('.rankingnews_list li'):
                a = li.select_one('a')
                if a and a.text.strip():
                    news_list.append({"title": a.text.strip(), "link": a['href']})
        return news_list[:30]
    except:
        return []

def get_news_body(url):
    try:
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        body = soup.select_one('#dic_area') or soup.select_one('#newsct_article')
        return body.get_text(strip=True) if body else "ë³¸ë¬¸ ìˆ˜ì§‘ ë¶ˆê°€"
    except:
        return "ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜"

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ‘‘ VIRAL MASTER PRO v2.6")

tab1, tab2 = st.tabs(["ğŸ”¥ ì‹¤ì‹œê°„ ì´ìŠˆ íƒìƒ‰", "ğŸ¯ ì´ˆê²©ì°¨ ì›ê³  ì œì‘"])

news_items = fetch_top_news()

with tab1:
    if news_items:
        if "s_class_indices" not in st.session_state:
            with st.spinner("ğŸš€ AI ì†Œì¬ ì„ ë³„ ì¤‘..."):
                titles_summary = "\n".join([f"{i}:{n['title'][:30]}" for i, n in enumerate(news_items)])
                select_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ì¤‘ ìœ íŠœë¸Œ ì¡°íšŒìˆ˜ê°€ ë†’ì„ë²•í•œ ì†Œì¬ 5ê°œ ë²ˆí˜¸ë§Œ ê³¨ë¼ì¤˜. [1,2,3] í˜•ì‹ìœ¼ë¡œ ë‹µë³€:\n{titles_summary}"
                selection_resp = call_gemini_api(select_prompt)
                if selection_resp:
                    try:
                        match = re.search(r"\[.*\]", selection_resp.text)
                        st.session_state.s_class_indices = json.loads(match.group()) if match else []
                    except:
                        st.session_state.s_class_indices = []
                else:
                    st.session_state.s_class_indices = []

        left_col, right_col = st.columns([1, 1])

        with left_col:
            st.subheader("ğŸ“° ì‹¤ì‹œê°„ ë­í‚¹ ë‰´ìŠ¤")
            if st.button("ğŸ”„ ë¦¬ìŠ¤íŠ¸ ìƒˆë¡œê³ ì¹¨"):
                st.cache_data.clear()
                if "s_class_indices" in st.session_state: del st.session_state.s_class_indices
                st.rerun()

            for i, item in enumerate(news_items):
                is_viral = i in st.session_state.get('s_class_indices', [])
                btn_label = f"ğŸ† [Sê¸‰] {item['title']}" if is_viral else f"[{i+1}] {item['title']}"
                
                if st.button(btn_label, key=f"news_btn_{i}"):
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        body_txt = get_news_body(item['link'])
                        analysis_resp = call_gemini_api(f"ë‹¤ìŒ ê¸°ì‚¬ ë¶„ì„(ì¸ë„¤ì¼ 3ê°œ, ìš”ì•½ 1ì¤„):\n{body_txt[:1000]}")
                        st.session_state.current_news = {
                            "title": item['title'],
                            "body": body_txt,
                            "analysis": analysis_resp.text if analysis_resp else "ë¶„ì„ ë¶ˆê°€ (API í•œë„ ì´ˆê³¼)",
                            "is_viral": is_viral
                        }

        with right_col:
            if "current_news" in st.session_state:
                data = st.session_state.current_news
                st.markdown(f"### {'ğŸ”¥ Sê¸‰ ì†Œì¬ ë¶„ì„' if data['is_viral'] else 'ğŸ“Š ì¼ë°˜ ì†Œì¬ ë¶„ì„'}")
                st.success(data['analysis'])
                st.text_area("ë‰´ìŠ¤ ì›ë¬¸", data['body'], height=400)
            else:
                st.info("ì™¼ìª½ ê¸°ì‚¬ë¥¼ í´ë¦­í•˜ì„¸ìš”.")

with tab2:
    st.header("ğŸ¯ ì›ê³  ë§ˆìŠ¤í„° ë¹Œë”")
    c_left, c_right = st.columns(2)
    with c_left:
        final_title = st.text_input("ğŸ’ ì œëª©")
        final_fact = st.text_area("ğŸ“° íŒ©íŠ¸", height=200)
    with c_right:
        final_target = st.text_input("ğŸ“º íƒ€ê²Ÿ URL")
        final_comment = st.text_area("ğŸ’¬ ëŒ“ê¸€ ë°˜ì‘", height=200)

    if st.button("ğŸ”¥ ì›ê³  í”„ë¡¬í”„íŠ¸ ìƒì„±"):
        if final_title and final_fact:
            script_prompt = f"ìœ íŠœë¸Œ ì‘ê°€ë¡œì„œ ì›ê³  ì‘ì„±.\nì œëª©: {final_title}\níŒ©íŠ¸: {final_fact}\níƒ€ê²Ÿ: {final_target}\në¯¼ì‹¬: {final_comment}"
            st.code(script_prompt, language="markdown")
            st.success("í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì„¸ìš”!")
