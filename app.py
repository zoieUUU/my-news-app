import streamlit as st
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai

# 1. AI ì—”ì§„ ì„¤ì • (ê°€ì¥ ì•ˆì „í•œ ëª¨ë¸ í˜¸ì¶œ ë°©ì‹)
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    # 'models/'ë¥¼ ë¹¼ê³  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì•Œì•„ì„œ ì°¾ë„ë¡ ì„¤ì •
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"API ì„¤ì • ì˜¤ë¥˜: {e}")

st.set_page_config(page_title="VIRAL RANKING MASTER", layout="wide")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (í—¤ë” ë³´ê°•ìœ¼ë¡œ ì°¨ë‹¨ ë°©ì§€) ---
@st.cache_data(ttl=600)
def get_viral_top_100():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"
    }
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    
    unique_news = []
    seen_titles = set()
    for box in soup.select('.rankingnews_box'):
        for li in box.select('.rankingnews_list li'):
            a_tag = li.select_one('a')
            if a_tag:
                title = a_tag.text.strip()
                if title not in seen_titles:
                    unique_news.append({"title": title, "link": a_tag['href']})
                    seen_titles.add(title)

    # TOP 5 ì†Œì¬ ì„ ë³„
    try:
        titles_list = "\n".join([f"{i}. {d['title']}" for i, d in enumerate(unique_news[:40])])
        prompt = f"ìœ íŠœë¸Œ ì¡°íšŒìˆ˜ ëŒ€ë°•ë‚  ì†Œì¬ 5ê°œì˜ ë²ˆí˜¸ë§Œ ê³¨ë¼ì¤˜(ì‰¼í‘œ êµ¬ë¶„): {titles_list}"
        resp = model.generate_content(prompt)
        s_indices = [int(x.strip()) for x in resp.text.split(',') if x.strip().isdigit()]
    except:
        s_indices = [0, 1, 2, 3, 4]
    
    for i, item in enumerate(unique_news):
        item['is_s'] = i in s_indices
    return sorted(unique_news, key=lambda x: x['is_s'], reverse=True)

# --- AI ë¶„ì„ í•¨ìˆ˜ (ë„¤ì´ë²„ ì°¨ë‹¨ ìš°íšŒ ë° íƒœê·¸ ì •ë°€í™”) ---
def get_ai_analysis(url):
    try:
        # í—¤ë”ì— Referer ì¶”ê°€ (ë„¤ì´ë²„ ì°¨ë‹¨ ìš°íšŒ í•µì‹¬)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36",
            "Referer": "https://news.naver.com/"
        }
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ìµœì‹  ë³¸ë¬¸ íƒœê·¸ ìˆœìœ„ë³„ ìˆ˜ì§‘
        content = soup.select_one('#dic_area') or \
                  soup.select_one('#newsct_article') or \
                  soup.select_one('#articleBodyContents') or \
                  soup.select_one('article')
        
        if not content:
            return "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¹„ë¡œê·¸ì¸ ì œí•œ ë˜ëŠ” íŠ¹ìˆ˜ ê¸°ì‚¬)", "ë¶„ì„ ì‹¤íŒ¨"
            
        text = content.get_text(separator="\n", strip=True)
        
        # AI ìš”ì•½
        analysis_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ [ìš”ì•½ 2ì¤„], [í‚¤ì›Œë“œ 5ê°œ]ë¡œ ë¶„ì„í•´ì¤˜:\n\n{text[:2000]}"
        resp = model.generate_content(analysis_prompt)
        return text, resp.text
    except Exception as e:
        return f"ì—°ê²° ì—ëŸ¬: {str(e)}", "ë¶„ì„ ì‹¤íŒ¨"

# --- í™”ë©´ êµ¬ì„± ---
st.title("ğŸ”¥ VIRAL RANKING MASTER")
st.markdown("### ğŸš€ ì‹¤ì‹œê°„ í†µí•© ë­í‚¹ : AI ì„ ì • ë°”ì´ëŸ´ S-CLASS")

l, r = st.columns([1, 1.2])

with l:
    if st.button("ğŸ”„ ë¦¬ìŠ¤íŠ¸ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()
    
    data = get_viral_top_100()
    
    for i, row in enumerate(data):
        if row['is_s']:
            st.markdown(f"""
                <div style="background-color: #FFD700; padding: 5px 10px; border-radius: 5px; border: 2px solid #FF8C00; margin-bottom: -10px;">
                    <b style="color: black; font-size: 13px;">ğŸ‘‘ AI S-CLASS ë°”ì´ëŸ´ ì¶”ì²œ</b>
                </div>
            """, unsafe_allow_html=True)
            if st.button(f"ğŸ”¥ {row['title']}", key=f"s_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = get_ai_analysis(row['link'])
                    st.session_state.cur_title, st.session_state.cur_text, st.session_state.cur_analysis = row['title'], t, a
            st.write("")
        else:
            if st.button(f"[{i+1}] {row['title']}", key=f"n_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = get_ai_analysis(row['link'])
                    st.session_state.cur_title, st.session_state.cur_text, st.session_state.cur_analysis = row['title'], t, a

with r:
    st.subheader("ğŸ“„ AI ë¶„ì„ ë¦¬í¬íŠ¸")
    if 'cur_title' in st.session_state:
        st.markdown("#### ğŸ’¡ í•µì‹¬ ìš”ì•½ ë° í‚¤ì›Œë“œ")
        # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë¬¸êµ¬ ëŒ€ì‹  ê°€ì´ë“œ ì¶œë ¥
        if "ë¶„ì„ ì‹¤íŒ¨" in st.session_state.cur_analysis:
            st.error("âš ï¸ AIê°€ ë³¸ë¬¸ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ì‚¬ ì›ë¬¸ì„ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            st.success(st.session_state.cur_analysis)
        
        st.divider()
        st.info(f"**ì œëª©: {st.session_state.cur_title}**")
        st.text_area("ê¸°ì‚¬ ë³¸ë¬¸", st.session_state.cur_text, height=500)
    else:
        st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ë‰´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
