import streamlit as st
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai

# 1. AI ì—”ì§„ ì„¤ì • (ê°€ìš© ëª¨ë¸ ìë™ íƒìƒ‰ ë¡œì§)
@st.cache_resource
def load_ai_model():
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        # í˜„ì¬ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # 1ìˆœìœ„: gemini-1.5-flash, 2ìˆœìœ„: gemini-pro, 3ìˆœìœ„: ì•„ë¬´ê±°ë‚˜ ì²« ë²ˆì§¸ ëª¨ë¸
        target_model = ""
        if 'models/gemini-1.5-flash' in models: target_model = 'models/gemini-1.5-flash'
        elif 'models/gemini-pro' in models: target_model = 'models/gemini-pro'
        else: target_model = models[0]
        
        return genai.GenerativeModel(target_model)
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

model = load_ai_model()

st.set_page_config(page_title="VIRAL RANKING MASTER", layout="wide")

# --- ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (ë„¤ì´ë²„ ì°¨ë‹¨ ë°©ì§€) ---
@st.cache_data(ttl=600)
def get_viral_top_100():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        unique_news = []
        seen_titles = set()
        for box in soup.select('.rankingnews_box'):
            for li in box.select('.rankingnews_list li'):
                a_tag = li.select_one('a')
                if a_tag and a_tag.text.strip() not in seen_titles:
                    unique_news.append({"title": a_tag.text.strip(), "link": a_tag['href']})
                    seen_titles.add(a_tag.text.strip())
        
        # Sê¸‰ ì¶”ì²œ (AI ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ ì‘ë™)
        s_indices = []
        if model:
            try:
                titles_list = "\n".join([f"{i}. {d['title']}" for i, d in enumerate(unique_news[:30])])
                resp = model.generate_content(f"ìœ íŠœë¸Œ ì¡°íšŒìˆ˜ í„°ì§ˆ ì†Œì¬ 5ê°œì˜ ë²ˆí˜¸ë§Œ ê³¨ë¼ì¤˜: {titles_list}")
                import re
                s_indices = [int(n) for n in re.findall(r'\d+', resp.text)]
            except: s_indices = [0,1,2,3,4]
        
        for i, item in enumerate(unique_news):
            item['is_s'] = i in s_indices
        return sorted(unique_news, key=lambda x: x.get('is_s', False), reverse=True)
    except: return []

# --- AI ë¶„ì„ í•¨ìˆ˜ ---
def get_ai_analysis(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0", "Referer": "https://news.naver.com/"}
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        content = soup.select_one('#dic_area') or soup.select_one('#newsct_article') or soup.select_one('#articleBodyContents')
        
        if not content: return "ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨", "ë¶„ì„ ë¶ˆê°€"
        text = content.get_text(strip=True)
        
        if model:
            resp = model.generate_content(f"ë‹¤ìŒ ë‰´ìŠ¤ ìš”ì•½ 2ì¤„, í‚¤ì›Œë“œ 5ê°œ ë½‘ì•„ì¤˜:\n\n{text[:1500]}")
            return text, resp.text
        return text, "AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì—°ê²° ì‹¤íŒ¨: {e}", "ë¶„ì„ ë¶ˆê°€"

# --- ë©”ì¸ í™”ë©´ ---
st.title("ğŸ”¥ VIRAL RANKING MASTER")

l, r = st.columns([1, 1.2])

with l:
    if st.button("ğŸ”„ ë¦¬ìŠ¤íŠ¸ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()
    
    data = get_viral_top_100()
    for i, item in enumerate(data):
        if item.get('is_s'):
            st.markdown(f'<div style="background-color:#FFD700; padding:5px; border-radius:5px; border:2px solid #FFA500; font-weight:bold; color:black; font-size:12px; margin-bottom:-10px; width:fit-content;">ğŸ‘‘ AI S-CLASS ì¶”ì²œ</div>', unsafe_allow_html=True)
            if st.button(f"ğŸ”¥ {item['title']}", key=f"s_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = get_ai_analysis(item['link'])
                    st.session_state.res = {"title": item['title'], "text": t, "analysis": a}
        else:
            if st.button(f"[{i+1}] {item['title']}", key=f"n_{i}", use_container_width=True):
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    t, a = get_ai_analysis(item['link'])
                    st.session_state.res = {"title": item['title'], "text": t, "analysis": a}

with r:
    st.subheader("ğŸ“Š AI ë¶„ì„ ë¦¬í¬íŠ¸")
    if "res" in st.session_state:
        st.success(f"**ğŸ’¡ AI ë¶„ì„ ê²°ê³¼**\n\n{st.session_state.res['analysis']}")
        st.divider()
        st.info(f"**ì œëª©: {st.session_state.res['title']}**")
        st.text_area("ê¸°ì‚¬ ë³¸ë¬¸", st.session_state.res['text'], height=550)
    else:
        st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ë‰´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
